Shell操作(常用操作)
1、 ls
用法1：hadoop fs -ls /
功能：列出hdfs文件系统根目录下的目录和文件
用法2：hadoop fs -ls -R /
功能：列出hdfs文件系统所有的目录和文件
2、 put
用法1：hadoop fs -put <local file> <hdfs file>    传文件  
功能：hdfs file的父目录一定要存在，否则命令不会执行
用法2：hadoop fs -put <local file or dir> <hdfs dir>  《dir  目录的意思》
功能：hdfs dir 一定要存在，否则命令不会执行
用法3：hadoop fs -put - <hdfs file>
功能：从键盘读取输入到hdfs file中，按Ctrl+D结束输入，hdfs file不能存在，否则命令不会执行
3、 moveFromLocal
用法：hadoop fs -moveFromLocal <local src> <hdfs dst> 《local本地 的意思  src  为路径》  <需要移动的文件>《移动到hdgs的目录》
功能：与put相类似，命令执行后源文件 local src 被删除，也可以从从键盘读取输入到hdfs file中
4、 copyFromLocal
用法：hadoop fs -copyFromLocal <local src> <hdfs dst>
功能：与put相类似，也可以从从键盘读取输入到hdfs file中
5、 get
用法1：hadoop fs -get <hdfs file> <local file or dir>
功能：local file不能和 hdfs file名字不能相同，否则会提示文件已存在，没有重名的文件会复制到本地
用法2：hadoop fs -get <hdfs file or dir> <local dir>
功能：拷贝多个文件或目录到本地时，本地要为文件夹路径
6、 moveToLocal
当前版本中还未实现此命令
7、 copyToLocal
用法：hadoop fs -copyToLocal <local src> <hdfs dst>
功能：与get相类似
8、 rm
用法1：hadoop fs -rm <hdfs file>
功能：删除文件
用法2：hadoop fs -rm -r <hdfs dir>
功能：删除目录
9、 mkdir
用法1：hadoop fs -mkdir <hdfs path>
功能：只能一级一级的建目录，父目录不存在的话使用这个命令会报错
用法2：hadoop fs -mkdir -p <hdfs path>
功能：所创建的目录如果父目录不存在就创建该父目录
10、 getmerge
用法1：hadoop fs -getmerge <hdfs dir> <local file>
功能：将hdfs指定目录下所有文件排序后合并到local指定的文件中，文件不存在时会自动创建，文件存在时会覆盖里面的内容
用法2：hadoop fs -getmerge -nl <hdfs dir> <local file>
功能：加上nl后，合并到local file中的hdfs文件之间会空出一行
11、 cp
用法1：hadoop fs -cp <hdfs file> <hdfs file>
功能：目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件还存在
用法2：hadoop fs -cp <hdfs file or dir> <hdfs dir>
功能：目标文件夹要存在，否则命令不能执行
12、 mv
用法1：hadoop fs -mv <hdfs file> <hdfs file>
功能：目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件不存在
用法2：hadoop fs -mv <hdfs file or dir> <hdfs dir>
功能：源路径有多个时，目标路径必须为目录，且必须存在。
注意：跨文件系统的移动（local到hdfs或者反过来）都是不允许的
13、 count
用法：hadoop fs -count <hdfs path>
功能：统计hdfs对应路径下的目录个数，文件个数，文件总计大小
14、 du
用法1：hadoop fs -du <hdfs path>
功能：显示hdfs对应路径下每个文件夹和文件的大小
用法2：hadoop fs -du -s <hdfs path>
功能：显示hdfs对应路径下所有文件和的大小
用法3：hadoop fs -du -h <hdfs path>
功能：显示hdfs对应路径下每个文件夹和文件的大小,文件的大小用方便阅读的形式表示，例如用64M代替67108864
15、 text
用法：hadoop fs -text <hdfs file>
功能：将文本文件或某些格式的非文本文件通过文本格式输出
16、 setrep
用法：hadoop fs -setrep -R 3 <hdfs path>
功能：改变一个文件在hdfs中的副本个数，上述命令中数字3为所设置的副本个数，-R选项可以对一个人目录下的所有目录+文件递归执行改变副本个数的操作
17、 stat
用法：hdoop fs -stat [format] <hdfs path>
功能：返回对应路径的状态信息
18、 tail
用法：hadoop fs -tail <hdfs file>
功能：在标准输出中显示文件末尾的1KB数据
19、 archive
用法：hadoop archive -archiveName filename -p /test 1.txt 2.txt /test1
功能：将hdfs中/test目录下的文件1.txt，2.txt压缩成一个名叫filename的文件存放在hdfs中/test1目录下，如果1.txt，2.txt不写就是将/test目录下所有的目录和文件压缩成一个名叫filename的文件存放在hdfs中/test1目录下。
主要作用就是将小文件归档，因为hadoop不适合管理小文件
20、balancer
用法：hdfs balancer
功能：如果管理员发现某些DataNode保存数据过多，某些DataNode保存数据相对较少，可以使用上述命令手动启动内部的均衡过程
21、 distcp
用法：hadoop distcp hdfs://hadoop1:9000/test hdfs://hadoop2:9000/test
功能：用来在两个HDFS之间拷贝数据
